{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing Data for ML Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is dependent on the execution of `scripts/02 - exploratory_data_analysis.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "print(\"Defining Classes\")\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.log_dir = config['logging']['out_dir']\n",
    "        self.tag = config['base']['tag']\n",
    "        self.file_path = os.path.join('outputs', self.tag, self.log_dir, 'log.txt')\n",
    "        self.verbose = config['logging']['verbose']\n",
    "        \n",
    "    def log(self, message):\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        datetime_string = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_message = f\"{datetime_string}: {message}\"\n",
    "        if self.verbose:\n",
    "            print(log_message)\n",
    "        with open(self.file_path, \"a\") as f:\n",
    "            f.write(f'{log_message}\\n')\n",
    "\n",
    "print(\"Defining Functions\")\n",
    "\n",
    "def loan_status_to_int(status):\n",
    "    if status == 'Charged Off':\n",
    "        return 0\n",
    "    if status == 'Fully Paid':\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def bestbandwidth(data):\n",
    "    return 1.06*np.std(data)*len(data)**(-1/5)\n",
    "\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return f\"Created directory: {directory}\"\n",
    "    else:\n",
    "        return f\"Directory already exists: {directory}\"\n",
    "\n",
    "def transform_type(sqlite_type):\n",
    "    if sqlite_type == 'INTEGER':\n",
    "        return 'int'\n",
    "    if sqlite_type == 'REAL':\n",
    "        return 'float'\n",
    "    if sqlite_type == 'TEXT':\n",
    "        return 'object'\n",
    "\n",
    "def map_dtype_to_sqlite(col_type):\n",
    "    if col_type.startswith('int') or col_type == 'bool':\n",
    "        return 'INTEGER'\n",
    "    elif col_type.startswith('float'):\n",
    "        return 'REAL'\n",
    "    else:  # Default case, particularly for 'object' and other unhandled types\n",
    "        return 'TEXT'\n",
    "\n",
    "print(\"Reading Config File\")\n",
    "\n",
    "config_file_path = '../config/config.yml'\n",
    "\n",
    "root_path = '..'\n",
    "\n",
    "print(f\"Reading Config File {config_file_path}\")\n",
    "with open(config_file_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Defining Variables and Creating Directories\")\n",
    "\n",
    "sqlite_file = config['data']['output_sqlite']\n",
    "\n",
    "tag = config['base']['tag']\n",
    "\n",
    "git_repo = config['base']['git_repo']\n",
    "\n",
    "fontsize = config['plotting']['fontsize']\n",
    "figsize_x = config['plotting']['figure_xsize']\n",
    "figsize_y = config['plotting']['figure_ysize']\n",
    "\n",
    "out_dir_figures = f\"outputs/{tag}/figures\"\n",
    "\n",
    "out_dir_stats = f\"outputs/{tag}/stats\"\n",
    "\n",
    "out_dir_log = f\"outputs/{tag}/log\"\n",
    "\n",
    "sqlite_file = os.path.join(f'{root_path}/outputs/{tag}/data/{sqlite_file}')\n",
    "out_dir_figures = os.path.join(root_path, out_dir_figures)\n",
    "out_dir_stats = os.path.join(root_path, out_dir_stats)\n",
    "out_dir_log = os.path.join(root_path, out_dir_log)\n",
    "\n",
    "columns_of_interest = config['base']['columns_of_interest']\n",
    "\n",
    "print(\"Done with initial setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning Data and Defining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Data\")\n",
    "# Defining the connection to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "# Loading descriptions into dataframe\n",
    "description_fetch_query = f\"\"\"SELECT *\n",
    "                    FROM descriptions\n",
    "                    \"\"\"\n",
    "descriptions = pd.read_sql_query(description_fetch_query, conn, index_col = 'name')\n",
    "\n",
    "column_types = {idx:transform_type(row['data_type']) for idx, row in descriptions.iterrows() if row['location'] == 'loans_data' and idx in columns_of_interest}\n",
    "\n",
    "# Loading data into dataframe\n",
    "data_fetch_query = f\"\"\"SELECT {', '.join(columns_of_interest)} \n",
    "                       FROM loans_data\n",
    "                       ORDER BY RANDOM()\"\"\"\n",
    "\n",
    "loans_data = pd.read_sql_query(data_fetch_query, conn, index_col='id', dtype=column_types)\n",
    "\n",
    "# Closing connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Filtering known bad columns\")\n",
    "\n",
    "loans_data = loans_data[loans_data['issue_d_unix'] != 0]\n",
    "\n",
    "print(\"Creating columns\")\n",
    "\n",
    "loans_data['issue_d'] = pd.to_datetime(loans_data['issue_d_unix'], unit='s')\n",
    "descriptions = pd.concat([descriptions, pd.DataFrame({\n",
    "    'name':['issue_d'],\n",
    "    'full_name': ['Issue Date'],\n",
    "    'type': ['Column'],\n",
    "    'location': ['loans_data'],\n",
    "    'description': ['Date the loan was issued'],\n",
    "    'data_type': ['TEXT']\n",
    "}).set_index('name')])\n",
    "\n",
    "loans_data['issue_month'] = loans_data['issue_d'].apply(lambda x: x.month)\n",
    "descriptions = pd.concat([descriptions, pd.DataFrame({\n",
    "    'name':['issue_month'],\n",
    "    'full_name': ['Issue Month'],\n",
    "    'type': ['Column'],\n",
    "    'location': ['loans_data'],\n",
    "    'description': ['Month of the year the loan was issued'],\n",
    "    'data_type': ['INT']\n",
    "}).set_index('name')])\n",
    "\n",
    "print(\"Limiting dataset to two types of Loan Status only\")\n",
    "\n",
    "loans_data = loans_data[(loans_data['loan_status'] == 'Charged Off') | (loans_data['loan_status'] == 'Fully Paid')]\n",
    "\n",
    "loans_data['loan_status'] = loans_data['loan_status'].apply(lambda x: x == 'Charged Off')\n",
    "\n",
    "print(\"Done with Loading and Cleaning Data and Defining Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Numerical and Dummy Columns, and Dropping Unecessary Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Declaring Numerical Columns\")\n",
    "numerical_columns = ['loan_status', 'loan_amnt', 'int_rate', 'installment', 'annual_inc', \n",
    "                     'dti', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
    "                     'mort_acc', 'pub_rec_bankruptcies']\n",
    "\n",
    "print(\"Declaring Dummy Columns\")\n",
    "dummy_columns = ['term_months', 'sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'initial_list_status', 'application_type']\n",
    "\n",
    "print(\"Declaring Columns to Drop\")\n",
    "drop_columns = ['grade', 'issue_d', 'issue_d_unix']\n",
    "\n",
    "print(\"Dropping Non-Interesting Columns\")\n",
    "loans_data_ML = loans_data.drop(drop_columns, axis='columns')\n",
    "print(\"Creating Dummy Columns\")\n",
    "loans_data_ML = pd.get_dummies(loans_data_ML, columns=dummy_columns, drop_first=True)\n",
    "\n",
    "print(\"Done Preparing Numerical and Dummy Columns, and Dropping Unecessary Ones\")\n",
    "loans_data_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving ML Prepared Data to new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Connecting to Database at {sqlite_file}\")\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "print(\"Creating Queries\")\n",
    "drop_loans_data_ML_query = 'DROP TABLE IF EXISTS loans_data_ML'\n",
    "\n",
    "# Query to create a table for the loans data\n",
    "create_loans_data_ML_table_query = 'CREATE TABLE loans_data_ML (' + ', '.join([f\"\\\"{col}\\\" {col_type}\" for col, col_type in zip(loans_data_ML.columns, [map_dtype_to_sqlite(str(loans_data_ML[col].dtype)) for col in loans_data_ML.columns])]) + ')'\n",
    "\n",
    "print(\"Dropping old tables and creating new ones\")\n",
    "# Drops and creates the tables\n",
    "conn.execute(drop_loans_data_ML_query)\n",
    "conn.execute(create_loans_data_ML_table_query)\n",
    "\n",
    "print(\"Loading data into tables\")\n",
    "# Insert data from DataFrame to the SQLite table\n",
    "loans_data_ML.to_sql('loans_data_ML', conn, if_exists='replace', index=True)\n",
    "\n",
    "conn.close()\n",
    "print(\"Done With Constructing the Database File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LendingClub",
   "language": "python",
   "name": "lendingclub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
